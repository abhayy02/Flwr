{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34cb429",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-03T14:49:56.556563Z",
     "iopub.status.busy": "2024-05-03T14:49:56.555466Z",
     "iopub.status.idle": "2024-05-03T14:51:30.361781Z",
     "shell.execute_reply": "2024-05-03T14:51:30.360692Z"
    },
    "papermill": {
     "duration": 93.814638,
     "end_time": "2024-05-03T14:51:30.365211",
     "exception": false,
     "start_time": "2024-05-03T14:49:56.550573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Set the paths to your dataset and the train/test folders\n",
    "data_dir = \"/kaggle/input/covid-19/Covid19\"\n",
    "train_dir = \"/kaggle/working/train\"\n",
    "test_dir = \"/kaggle/working/test\"\n",
    "\n",
    "# Create the train and test folders if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Create subfolders for the classes (Normal and Covid-19)\n",
    "os.makedirs(os.path.join(train_dir, \"Normal\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(train_dir, \"COVID\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_dir, \"Normal\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_dir, \"COVID\"), exist_ok=True)\n",
    "\n",
    "# Set the train/test split ratio (e.g., 0.8 for 80% train, 0.2 for 20% test)\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Loop through the classes\n",
    "for class_name in [\"Normal\", \"COVID\"]:\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    files = os.listdir(class_dir)\n",
    "    \n",
    "    # Shuffle the files randomly\n",
    "    random.shuffle(files)\n",
    "    \n",
    "    # Calculate the number of files for train and test sets\n",
    "    num_train = int(len(files) * train_ratio)\n",
    "    \n",
    "    # Copy the files to the train and test folders\n",
    "    for i, file in enumerate(files):\n",
    "        src = os.path.join(class_dir, file)\n",
    "        if i < num_train:\n",
    "            dst = os.path.join(train_dir, class_name, file)\n",
    "        else:\n",
    "            dst = os.path.join(test_dir, class_name, file)\n",
    "        shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "697d62c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T14:51:30.374361Z",
     "iopub.status.busy": "2024-05-03T14:51:30.374034Z",
     "iopub.status.idle": "2024-05-03T14:52:01.583183Z",
     "shell.execute_reply": "2024-05-03T14:52:01.581728Z"
    },
    "papermill": {
     "duration": 31.216358,
     "end_time": "2024-05-03T14:52:01.585809",
     "exception": false,
     "start_time": "2024-05-03T14:51:30.369451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 23.8.0 requires cubinlinker, which is not installed.\r\n",
      "cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 23.8.0 requires ptxcompiler, which is not installed.\r\n",
      "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.3 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\r\n",
      "cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\r\n",
      "cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "cudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\r\n",
      "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.25.3 which is incompatible.\r\n",
      "google-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\r\n",
      "google-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 4.25.3 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\r\n",
      "kfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\r\n",
      "pyopenssl 23.3.0 requires cryptography<42,>=41.0.5, but you have cryptography 42.0.5 which is incompatible.\r\n",
      "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 4.25.3 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\r\n",
      "tensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\r\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires pydantic>=2, but you have pydantic 1.10.15 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q flwr[simulation] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7548281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T14:52:01.594425Z",
     "iopub.status.busy": "2024-05-03T14:52:01.594038Z",
     "iopub.status.idle": "2024-05-03T15:03:12.859352Z",
     "shell.execute_reply": "2024-05-03T15:03:12.858179Z"
    },
    "papermill": {
     "duration": 671.273279,
     "end_time": "2024-05-03T15:03:12.862262",
     "exception": false,
     "start_time": "2024-05-03T14:52:01.588983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 14:52:09.951113: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-03 14:52:09.951232: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-03 14:52:10.067196: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-03 14:52:20,518\tINFO util.py:129 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:503: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda using PyTorch 2.1.2\n",
      "Label(value='The size of data: 13808')\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=10, no round_timeout\n",
      "2024-05-03 14:52:24,272\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'object_store_memory': 8936927232.0, 'GPU': 2.0, 'node:__internal_head__': 1.0, 'node:172.19.2.2': 1.0, 'CPU': 4.0, 'memory': 17873854464.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 1}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(pid=265)\u001b[0m 2024-05-03 14:52:29.112218: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[2m\u001b[36m(pid=265)\u001b[0m 2024-05-03 14:52:29.112283: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[2m\u001b[36m(pid=265)\u001b[0m 2024-05-03 14:52:29.113842: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 7] fit, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 5] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 8 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 1] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 8 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 9] fit, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 6] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 8] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 8 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 0] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 8 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 4] evaluate, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 8] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 8 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 7] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 8 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 6] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 8 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 8] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 8 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 2] fit, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 8] evaluate, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 7] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 8 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 8] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 8 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 7] fit, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 6] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 8 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 1] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 8 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 5] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 8 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 2] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 8 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 6] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 7] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 8 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 2] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 8 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 7] fit, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 8 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 6] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 8 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 4] evaluate, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 5] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=265)\u001b[0m [Client 7] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 8 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=266)\u001b[0m [Client 8] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 8 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 10 rounds in 645.72s\n",
      "\u001b[92mINFO \u001b[0m:      History (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t('\\tround 1: 0.3765134450386871\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 2: 0.025620914521542464\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 3: 0.025075374272736636\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 4: 0.023760506646199664\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 5: 0.022518874975768002\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 6: 0.021209802207621663\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 7: 0.021178319101983853\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 8: 0.021125895021991296\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 9: 0.021958002515814524\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 10: 0.021599010259590365\\n')History (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.8043047295383743),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.34664401019541197),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.8530161427357689),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.8462192013593881),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 0.8416879071084677),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (6, 0.8439535542339279),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (7, 0.8382894364202774),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (8, 0.8382894364202775),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (9, 0.8371566128575474),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (10, 0.8462192013593881)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import flwr as fl\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import IPython.display as display_output\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from collections import OrderedDict\n",
    "from typing import List, Tuple\n",
    "from IPython.display import display, clear_output\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from flwr.common import Metrics\n",
    "from flwr.server.strategy import FedAdam\n",
    "global num_c, trainloaders, valloaders, testloader, model, classes\n",
    "num_clients=10\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"  # Required for Kaggle to work with PyTorch\n",
    "\n",
    "torch.cuda.is_available()  # Check if GPU is available\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\n",
    "    f\"Training on {DEVICE} using PyTorch {torch.__version__}\"\n",
    ")\n",
    "# Dataset paths\n",
    "dataset_paths = '/kaggle/working/'\n",
    "\n",
    "datatrain = f'{dataset_paths}/train'\n",
    "datatest = f'{dataset_paths}/test'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "img_size = (224, 224)\n",
    "\n",
    "# Download and transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "trainset = ImageFolder(datatrain, transform=transform)\n",
    "testset = ImageFolder(datatest, transform=transform)\n",
    "size_label = widgets.Label()\n",
    "size_label.value = f'The size of data: {len(trainset) + len(testset)}'\n",
    "print(size_label)\n",
    "\n",
    "# Get the classes from the trainset\n",
    "classes = trainset.classes\n",
    "num_c = len(classes)\n",
    "\n",
    "# Split training set into num_clients partitions to simulate the individual dataset\n",
    "partition_size = len(trainset) // num_clients\n",
    "remainder = len(trainset) % num_clients\n",
    "lengths = [partition_size + remainder] + [partition_size] * (num_clients - 1)\n",
    "datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "# Split each partition into train/val and create DataLoader\n",
    "trainloaders = []\n",
    "valloaders = []\n",
    "for ds in datasets:\n",
    "    len_val = len(ds) // 10  # 10 % validation set\n",
    "    len_train = len(ds) - len_val\n",
    "    lengths = [len_train, len_val]\n",
    "    ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "    trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "    print(\"hi\")\n",
    "    valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_c):\n",
    "        super(Net, self).__init__()\n",
    "        self = self.to(DEVICE)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 264)\n",
    "        self.fc2 = nn.Linear(264,num_c)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "def train(net, trainloader, epochs: int, verbose=False):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n",
    "\n",
    " \n",
    "def aggregation_FedAdam(metrics: List[Tuple[int, dict]]) -> dict:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    total_examples = sum(examples)\n",
    "    weighted_acc_sum = sum(accuracies)\n",
    "\n",
    "    # Apply FedAdam strategy (e.g., update the weighted average with global update)\n",
    "    global_update = 0.1  # Replace with the appropriate global update value\n",
    "\n",
    "    weighted_acc_sum += global_update * total_examples\n",
    "    total_examples += global_update\n",
    "\n",
    "    return {\"accuracy\": weighted_acc_sum / total_examples}\n",
    "\n",
    "def fit_metrics_aggregation_fn(fit_metrics):\n",
    "    # Aggregate and return custom metric (e.g., weighted average)\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in fit_metrics]\n",
    "    examples = [num_examples for num_examples, _ in fit_metrics]\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "class FlowerNumPyClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        \n",
    "        # Get the accuracy on the training set\n",
    "        correct, total = 0, 0\n",
    "        self.net.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.trainloader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = self.net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        accuracy = correct / total\n",
    "        \n",
    "        return get_parameters(self.net), len(self.trainloader), {\"accuracy\": float(accuracy)}\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "    \n",
    "    \n",
    "def client_fn(cid) -> FlowerNumPyClient:\n",
    "    net = Net(num_c).to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    flower_numpy_client = FlowerNumPyClient(cid, net, trainloader, valloader)\n",
    "    return flower_numpy_client.to_client()\n",
    "\n",
    "\n",
    "\n",
    "def run_simulation(num_round,strategy_dropdown):   \n",
    "    if strategy_dropdown == \"FedAdam\":\n",
    "        # Start simulation with FedAdam strategy\n",
    "        strategy = FedAdam(\n",
    "            fraction_fit=1.0,\n",
    "            fraction_evaluate=0.5,\n",
    "            min_fit_clients=num_clients - 1,\n",
    "            min_evaluate_clients=num_clients - 2,\n",
    "            min_available_clients=num_clients,\n",
    "            evaluate_metrics_aggregation_fn=aggregation_FedAdam,\n",
    "            initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net(num_c))),\n",
    "            eta=1e-1,  # Adjust the learning rate if needed\n",
    "            eta_l=1e-1,  # Adjust the client-side learning rate if needed\n",
    "            beta_1=0.9,  # Adjust the momentum parameter if needed\n",
    "            beta_2=0.99,  # Adjust the second moment parameter if needed\n",
    "            tau=1e-9,\n",
    "        )\n",
    "\n",
    "    # Update with your specific simulation code\n",
    "    fl.common.logger.configure(identifier=\"myFlowerExperiment\", filename=\"log.txt\")\n",
    "    output = fl.simulation.start_simulation(\n",
    "        client_fn=client_fn,\n",
    "        num_clients=num_clients,\n",
    "        config=fl.server.ServerConfig(num_rounds=num_round),\n",
    "        strategy=strategy,\n",
    "        client_resources={\"num_cpus\": 1, \"num_gpus\": 1},\n",
    "    )\n",
    "\n",
    "run_simulation(10,\"FedAdam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a57a64b",
   "metadata": {
    "papermill": {
     "duration": 0.017714,
     "end_time": "2024-05-03T15:03:12.898508",
     "exception": false,
     "start_time": "2024-05-03T15:03:12.880794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4920800,
     "sourceId": 8284930,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 804.530387,
   "end_time": "2024-05-03T15:03:18.042358",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-03T14:49:53.511971",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "8b7d09ded4fe496897c3bc511767e9c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a837631420f149b386c5bdd1ff23592f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d2c9ce1fb42b467bb6bdbc61f9ce8244": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8b7d09ded4fe496897c3bc511767e9c9",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_a837631420f149b386c5bdd1ff23592f",
       "value": "The size of data: 13808"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
